Aclaración: Estas son respuestas dadas de manera propia y no reflejan de ninguna manera alguna opinión o definición del sitio oficial

The Case for Hadoop
1. 3 V's
volume: amoung of data tha supere the capacity of tools used to process and query (ZB)
velocity: when the architecture came a problem to consume the data
variety: diferents kinds of data and sources


2. Next two data size classification beyond Petabyte

ExaBytes
ZetaByte

3. Open HortonWorks

4. 	Data Discovery
	Predictive Analytics
	

The Hadoop Ecosystem

1. Match the components with architectural categories

Ambari Operations
Hbase:  Data Access
HDFS: Data Management
Sqoop: Governance and Integrations
Ranger: Security

2. The number of master nodes grows in proportion to the number of workers
R: False

3. List a few types of data sources thar are new to most organizations
Json
Xml
Streaming

4. Hadoop's goal is to displace all existing data systems.
R: False

HDFS Architecture

1. HDFS break files into _big blocks_ and perssist multiple _distributions_ across the cluster to aid in the file system's _fails_
and the to help programs obtain _data_
2. NameNode
3. DataNode
4. False
5. True

Ingesting Data
1. Sqoop
2. Script Hadoop Client, Script Sqoop
3.False
4. Storm